{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc00cfcc-0ea1-483d-8f07-906c751978f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a8f9e-2c21-4d08-a775-fc827894445b",
   "metadata": {},
   "source": [
    "# we can use github src for splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462f09d-2258-4a86-b3cf-275588a1010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -o train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/main/utils/train_val_split.py\n",
    "# !curl -o yolo_detect.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/yolo_detect.py\n",
    "# TO DO: Improve robustness of train_val_split.py script so it can handle nested data folders, etc\n",
    "!python train_val_split.py --datapath=\"data/path\" --train_pct=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "248064a4-7977-43c2-9212-23dc02998b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 16 22:53:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 571.96                 Driver Version: 571.96         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 ...  WDDM  |   00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   45C    P8              6W /   35W |     867MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           15108      C   ...\\envs\\YOLO_pytorch\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2155a3a-dd3a-4443-a48d-61b02cb8988d",
   "metadata": {},
   "source": [
    "# visualizing\n",
    "* video\n",
    "* image\n",
    "* folder\n",
    "* camera\n",
    "* pi\n",
    "* phone camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd41b496-60dc-48cf-86e0-0817463924a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images processed. Exiting...\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "model_path = \"casting_yolo11l.pt\"\n",
    "img_source = \"casting test\"\n",
    "user_res = \"720x720\" # (w,h)\n",
    "myiou = 0.7\n",
    "myconf = 0.5\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Model path is invalid\")\n",
    "    sys.exit(0)\n",
    "\n",
    "model = YOLO(model_path, task='detect')\n",
    "labels = model.names\n",
    "\n",
    "img_format = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.bmp', '.BMP']\n",
    "vid_format = ['.avi', '.mov', '.mp4', '.mkv', '.wmv']\n",
    "\n",
    "if os.path.isdir(img_source):\n",
    "    source_type = \"folder\"\n",
    "    if len(os.listdir(img_source)) == 0:\n",
    "        print('Empty folder')\n",
    "        sys.exit(0)   \n",
    "elif os.path.isfile(img_source):\n",
    "    _, ext = os.path.splitext(img_source)\n",
    "    if ext in img_format:        \n",
    "        source_type = \"image\"       \n",
    "    elif ext in vid_format:\n",
    "        source_type = \"video\"\n",
    "    else:\n",
    "        print(\"Unsupported image or video format\")\n",
    "        sys.exit(0)\n",
    "elif \"usb\" in img_source:\n",
    "    source_type = \"usb\"\n",
    "    usb_idx = int(img_source[3:])\n",
    "elif \"picamera\" in img_source:\n",
    "    source_type = \"picamera\"\n",
    "    picam_idx = int(img_source[8:])\n",
    "else:\n",
    "    print(\"Unsupported camera format (img_source)\")\n",
    "    sys.exit(0)\n",
    "\n",
    "resize = False\n",
    "if user_res:\n",
    "    width,height = int(user_res.split(\"x\")[0]), int(user_res.split(\"x\")[1])\n",
    "    resize=True\n",
    "\n",
    "if source_type==\"image\":\n",
    "    image = [img_source]\n",
    "elif source_type==\"folder\":\n",
    "    img_list = []\n",
    "    file_list = glob.glob(img_source+\"/*\")\n",
    "    for file in file_list:\n",
    "        _,ext = os.path.splitext(file)\n",
    "        if ext in img_format:\n",
    "            img_list.append(os.path.join(file))\n",
    "elif source_type in [\"usb\",\"video\"] :\n",
    "    if source_type == \"usb\" : cap_arg = usb_idx\n",
    "    elif source_type == \"video\" : cap_arg = img_source\n",
    "    cap = cv2.VideoCapture(cap_arg)\n",
    "    if user_res:\n",
    "        ret = cap.set(3,height)\n",
    "        ret = cap.set(4,width)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        recorded = cv2.VideoWriter(\"VideoRecorder/record1.avi\",fourcc,20.0,(width,height))\n",
    "        \n",
    "elif source_type==\"picamera\":\n",
    "    from picamera2 import Picamera2\n",
    "    cap = Picamera2()\n",
    "    cap.configure(cap.create_video_configuration(main={\"format\": 'XRGB8888', \"size\": (resW, resH)}))\n",
    "    cap.start()\n",
    "    \n",
    "def overlay_text_on_frame(frame, text, position,text_color,font_size):\n",
    "            font_path = \"Vazir.ttf\"    \n",
    "            pil_image = Image.fromarray(frame)\n",
    "            reshaped_text = arabic_reshaper.reshape(text)\n",
    "            bidi_text = get_display(reshaped_text)\n",
    "            font = ImageFont.truetype(font_path, font_size)\n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "            draw.text(position, bidi_text, font=font, fill=text_color)\n",
    "            return np.array(pil_image)\n",
    "    \n",
    "image_count = 0\n",
    "damaged_count = 0\n",
    "ok_count = 0\n",
    "avg_fps = 0\n",
    "fps_array= []\n",
    "line_x = (width-240)//2     \n",
    "line_x2 = (width-280)//2\n",
    "while True:\n",
    "    start_t = time.perf_counter()\n",
    "    if source_type == \"folder\":\n",
    "        if image_count >= len(img_list):\n",
    "            print('All images processed. Exiting...')\n",
    "            break\n",
    "        frame = cv2.imread(img_list[image_count])\n",
    "        image_count += 1\n",
    "    elif source_type==\"usb\" or source_type==\"video\":\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None :\n",
    "            print(\"camera disconnected or video has finished\")\n",
    "            break\n",
    "    elif source_type==\"image\":  \n",
    "         frame = cv2.imread(img_source)\n",
    "    elif source_type == 'picamera':\n",
    "        frame_bgra = cap.capture_array()\n",
    "        frame = cv2.cvtColor(np.copy(frame_bgra), cv2.COLOR_BGRA2BGR)\n",
    "        if (frame is None):\n",
    "            print('Unable to read frames from the Picamera. This indicates the camera is disconnected or not working. Exiting program.')\n",
    "            break\n",
    "\n",
    "    if resize==True:\n",
    "        frame = cv2.resize(frame,(width,height))\n",
    "        \n",
    "    results = model.predict(frame,verbose=False,iou=myiou) # new version but decrease speed\n",
    "    predict = results[0].boxes\n",
    "    object_count = 0\n",
    "    fps = 20.0\n",
    "    bbox_color = [(0,0,200),(0,200,0)]\n",
    "    detections = []\n",
    "    area_detections = []\n",
    "    for i in range(len(predict)):\n",
    "        conf = predict[i].conf.item()\n",
    "        \n",
    "        if conf > myconf :             \n",
    "            x1, y1, x2, y2 = map(int, predict[i].xyxy[0]) # bbox\n",
    "            label = results[0].names[int(predict[i].cls[0])] # class \n",
    "            bbox = [x1,y1,x2-x1,y2-y1] \n",
    "            color = bbox_color[0] if label == \"damaged\" else bbox_color[1] \n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),color,1)\n",
    "            area_detections.append(bbox[2] * bbox[3])\n",
    "            if conf > 0.6 and bbox[2] * bbox[3] > 30000:\n",
    "                \n",
    "                centroid_x = (x1+x2)//2\n",
    "                if line_x > centroid_x>line_x2:\n",
    "                    if label==\"damaged\":\n",
    "                        damaged_count+=1\n",
    "                    else :\n",
    "                        ok_count+=1\n",
    "                    \n",
    "            text = f\"{label}  {conf*100:.0f}\"\n",
    "            color = bbox_color[0] if label == \"damaged\" else bbox_color[1]          \n",
    "            labelSize, baseline = cv2.getTextSize(text,cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)           \n",
    "            cv2.rectangle(frame, (x1, y1-labelSize[1]-10), (x1+labelSize[0]+6, y1+baseline-10), color, cv2.FILLED)\n",
    "            cv2.putText(frame, text, (x1+4, y1 - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "            object_count+=1\n",
    "        \n",
    "    frame = overlay_text_on_frame(frame, \"خراب\", (width-60,20),(0,0,200),25)\n",
    "    frame = overlay_text_on_frame(frame, \"سالم\", (width-60,50),(0,200,100),25)\n",
    "    cv2.putText(frame, f\" {damaged_count}\",(width-120,45),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,200),2)\n",
    "    cv2.putText(frame, f\" {ok_count}\",(width-120,80),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,200,100),2)              \n",
    "    cv2.line(frame,((width-250)//2,0),((width-250)//2,height),(0,230,0),2)\n",
    "    # cv2.line(frame,((width-300)//2,0),((width-300)//2,height),(0,230,0),2)    \n",
    "            \n",
    "    if source_type in [\"video\",\"usb\",\"picamera\"]:         \n",
    "        cv2.putText(frame,f\"average FPS : {avg_fps:.2f}\",(10,20),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,200,100),2)\n",
    "    frame = overlay_text_on_frame(frame, \"عدد در دید\", (10,27),(0,200,100),25)    \n",
    "    cv2.putText(frame, f\" {object_count}\",(130,55),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,100,200),2)\n",
    "    \n",
    "    cv2.imshow(\"prediction\",frame)\n",
    "    # if record: recorded.write(frame)\n",
    "    recorded.write(frame)       \n",
    "    key = cv2.waitKey(1 if source_type in [\"video\", \"usb\", \"picamera\"] else 0)\n",
    "    if key == ord(\"s\") or key == ord(\"S\"): # save\n",
    "        cv2.imwrite(\"screenshots/screen.png\",frame)\n",
    "    elif key == ord(\"p\") or key == ord(\"P\"): # pause\n",
    "        cv2.waitKey()\n",
    "    elif key == ord('q') or key == ord('Q'): # quit\n",
    "        break\n",
    "        \n",
    "    end_t = time.perf_counter()\n",
    "    fps_array.append(float(1/(end_t-start_t)))\n",
    "    avg_fps = sum(fps_array) / len(fps_array)\n",
    "    \n",
    "\n",
    "if source_type == 'video' or source_type == 'usb':\n",
    "    print(f'average FPS: {avg_fps:.2f}')\n",
    "    # print(np.mean(area_detections))\n",
    "    print(f\"ok: {ok_count}\")\n",
    "    print(f\"damaged: {damaged_count}\")\n",
    "    cap.release()\n",
    "elif source_type == 'picamera':\n",
    "    cap.stop()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4105143-0471-4ac6-90bc-53c7971c2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FPS: 21.97\n",
      "ok: 1\n",
      "damaged: 2\n"
     ]
    }
   ],
   "source": [
    "# just video (fast version)\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL_PATH = \"casting_yolo11l.pt\"\n",
    "SOURCE = \"photo.mp4\"\n",
    "RESOLUTION = \"720x720\"  # (w, h)\n",
    "IOU_THRESH = 0.7\n",
    "CONF_THRESH = 0.5\n",
    "BBOX_COLORS = [(0, 0, 200), (0, 200, 0)]\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(\"Model path is invalid\")\n",
    "\n",
    "model = YOLO(MODEL_PATH, task='detect')\n",
    "\n",
    "crossed_ids = set()\n",
    "damaged_count = 0\n",
    "ok_count = 0\n",
    "fps_array = []\n",
    "\n",
    "width, height = map(int, RESOLUTION.split(\"x\"))\n",
    "cap = cv2.VideoCapture(SOURCE)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(\"VideoRecorder/recorded2_fast_yolo11l.avi\", fourcc, 20.0, (width, height))\n",
    "\n",
    "line_x = (width - 40) // 2\n",
    "line_x2 = (width - 60) // 2\n",
    "\n",
    "def process_frame(frame):\n",
    "    global damaged_count, ok_count\n",
    "    results = model.predict(frame, verbose=False, iou=IOU_THRESH, conf=CONF_THRESH)\n",
    "    detections = []\n",
    "    for box in results[0].boxes:\n",
    "        \n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = box.conf.item()\n",
    "        label = results[0].names[int(box.cls[0])]\n",
    "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, label))\n",
    "\n",
    "    for bbox, conf, label in detections:\n",
    "        color = BBOX_COLORS[0] if label == \"damaged\" else BBOX_COLORS[1]\n",
    "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), color, 2)\n",
    "        text = f\"{label} {conf * 100:.0f}\"\n",
    "        labelSize, baseline = cv2.getTextSize(text,cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)           \n",
    "        cv2.rectangle(frame, (x1, y1-labelSize[1]-10), (x1+labelSize[0]+6, y1+baseline-10), color, cv2.FILLED)\n",
    "        cv2.putText(frame, text, (x1+3, y1 - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
    "\n",
    "        centroid_x = (bbox[0] + bbox[0] + bbox[2]) // 2\n",
    "        if line_x > centroid_x > line_x2:\n",
    "            if label == \"damaged\":\n",
    "                damaged_count += 1\n",
    "            else:\n",
    "                ok_count += 1\n",
    "\n",
    "    return frame, len(detections)\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.perf_counter()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "    processed_frame, object_count = process_frame(frame)\n",
    "\n",
    "    cv2.putText(processed_frame, f\"Damaged: {damaged_count}\", (width - 160, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, BBOX_COLORS[0], 2)\n",
    "    cv2.putText(processed_frame, f\"OK: {ok_count}\", (width - 160, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, BBOX_COLORS[1], 2)\n",
    "    cv2.putText(processed_frame, f\"Total: {object_count}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 200, 100), 2)\n",
    "    cv2.line(frame,((width-250)//2,0),((width-250)//2,height),(0,230,0),2)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    fps = 1 / (end_time - start_time)\n",
    "    fps_array.append(fps)\n",
    "    avg_fps = sum(fps_array) / len(fps_array)\n",
    "    cv2.putText(processed_frame, f\"Avg FPS: {avg_fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 200, 100), 2)\n",
    "\n",
    "    cv2.imshow(\"Object Counting\", processed_frame)\n",
    "    out.write(processed_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "print(f\"ok: {ok_count}\")\n",
    "print(f\"damaged: {damaged_count}\")\n",
    "# 1 less counted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
